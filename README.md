## Automation POC - Java | Selenium | Selenide | Allure Report | Docker | CI/CD
[![Run Tests CI](https://github.com/DaviBFarias/automation-poc/actions/workflows/running-scripts.yml/badge.svg?branch=main)](https://github.com/DaviBFarias/automation-poc/actions/workflows/running-scripts.yml)

# A Proof of Concept Using Integrated Tech Stacks
1. [Introduction](#1-introduction)
2. [Core Technology Stack](#2-core-technology-stacks)
3. [Project Planning](#3-project-planning)
4. [Project Structure](#4-project-structure)
5. [Challenges in Object Mapping](#5-challenges-in-object-mapping)
6. [Instructions to run the project](#6-instructions-to-run-the-project)

## 1. Introduction:
Good day everyone,

I want to share insights into a Proof of Concept (POC) project. This project was aimed at optimizing our testing processes using integrated tech stacks comprising of Java, Selenium, Selenide, Allure Report, Docker, and Continuous Integration/Continuous Deployment (CI/CD) using GitHub Actions pipeline.

The motivation behind this initiative was to embrace modern testing frameworks and technologies to accelerate our delivery timelines, enhance the reliability of our applications, and foster a culture of continuous improvement within our development teams.

Hereâ€™s a snapshot of what the project entailed:

## 2. Core Technology Stacks:
   - **Java**: Chosen for its robustness and vast community support, it served as the backbone of our automation codebase.
   - **Selenium and Selenide**: These powerful libraries facilitated sophisticated browser interactions, making our tests more intuitive and maintainable.
   - **Allure Report**: It provided a clear and comprehensive reporting mechanism, enabling us to swiftly identify and resolve issues in SUT or scripts.
   - **Docker**: By containerizing our testing environments, Docker ensured consistent test executions and simplified our deployment processes.
   - **CI/CD**: Implementing CI/CD pipelines allowed for streamlined, automated testing and delivery, reducing manual intervention and promoting a faster feedback loop.

---
## 3. Project Planning:
  First of all, it was necessary to understand the System Under Test (SUT), its particularities, and its functionalities to define the main scopes and to determine which part of the system would be prioritized. The SUT in question is the training page of OutSystems (https://learn.outsystems.com/training).

In my analysis, I chose the following 3 test cases to be automated:

CT_1 - User authentication

CT_2 - Access the course through search and filter by tags

CT_3 - Start a training journey

My planning was organized, prioritized, and managed using this [GitHub Project](https://github.com/users/DaviBFarias/projects/1)

## 4. Project Structure:
   - **BDD**: Most of the team in a company were not from the IT area, so having concise test cases that are readable by anyone and linked with the test definitions is helpful for the entire team.
   - **Page Object Model (POM)**: Promotes code reusability and readability, which enhances maintainability and reduces script maintenance cost in automated testing.
   - **Helpers and Page Bases**: Useful methods can save time and standardize approaches on how to interact with similar elements.
   - **Integration**: The choice of libraries is crucial to reap the benefits of fewer configurations.

## 5. Challenges in Object Mapping:
- The SUT (System Under Test) is highly hierarchical, with a substantial chaining of objects.
- The types of objects are not reliable. It looks like a button, but it's not.
- Few unique properties in the objects.
- Loading between pages and effects on interaction with objects.

These and other behaviors were identified in the SUT, presenting a great challenge for automation. Analyzing and understanding the system behavior is essential. Some of the techniques applied to overcome these issues included:

- Systems generated by codeless tools often have these same types of more dynamic objects, but usually end up having a table structure or lists most of the time. Enhanced features to handle lists are very helpful; Selenide is great for this with its $$ selectors and native methods for list validation.
- Knowing when to wait for objects is also essential, so always before interacting with an object, it was necessary to validate that it is enabled, visible, or even interactable.
- Using anchors or locating an object contained within another greatly helped in dealing with the hierarchy of elements.

## 6. Instructions to run the project:

This project was developed thinking in CI/CD integration, so there are 4 ways to run it:
- Local watching execution;
- Local headless;
- Running a workflow
- Pushing something to the main branch (Automated execution)

For the local execution, the project requires a valid email and password for a registered user in the training OutSystems platform.
If you don't have it, create one here: https://www.outsystems.com/Platform/Signup

#### Windows environment used to create the scripts (Consider this as a requirement):
- JDK 11 (take a look here how to install and configure it: [Guide -by phoenixnap](https://phoenixnap.com/kb/install-java-windows))
- Maven 3.8.1 (take a look here how to install and configure it: [Guide -by phoenixnap](https://phoenixnap.com/kb/install-maven-windows))
- Git

### Running local and watching the execution
- Clone this repository
~~~
git clone https://github.com/DaviBFarias/automation-poc.git
~~~

- Open the cloned repository in the terminal and run to start the script

Use one of the possible tags: @outsystems-training, @authentication-user, @courses-search-filter-tag, or @journeys-starting-journey
Full execution @outsystems-training takes around 5 minutes.
Keep the "clean" in command for generating a new allure report at the end, and remove it to increment report with more executions
~~~
mvn clean test -Dcucumber.filter.tags="@outsystems-training" -Dselenide.headless=false
~~~
-Dselenide.headless=false can be set in code or selenide.properties, but in command is easier.

### Running local and headless
~~~
mvn clean test -Dcucumber.filter.tags="@outsystems-training" -Dselenide.headless=true
~~~
#### Generating Allure Report Manually
~~~
mvn allure:report
~~~

### Running on a Workflow

Access Actions Workflows: https://github.com/DaviBFarias/automation-poc/actions/workflows/running-scripts.yml

Run the workflow:
![Workflow Image](https://i.imgur.com/z3ciicF.png)

### Running When Pushing Something to the Main Branch (Automated Execution)

This is the goal! 
In a real routine, we want things to happen without needing to do anything, allowing us to stay focused on the main points and use our time to be productive and improve the quality process.

Here is how it happens:
- The project has a Dockerfile with everything needed to create a Docker image to run the tests. When a merge is pushed to the main branch, the workflow will be triggered.
- The workflow communicates with a GitHub runner, and it will build the Docker image on a VPS.
- The workflow will check out the project and run it on the Docker container.
- After finishing the execution, the Allure Report will be generated and published.
![Report Image](https://i.imgur.com/mg6vlIJ.png)
You can see the execution report here: [Link to Report](http://157.230.69.180/allure-report)

Thank you!
